{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport numpy as np\nimport pandas as pd\nfrom enum import Enum\n\n# --- small‐config for quick debugging ---\nclass SmallConfig:\n    def __init__(self):\n        self.d_model = 64\n        self.n_layers = 2\n        self.d_state = 16\n        self.d_conv = 3\n        self.expand = 2\n        self.dt_rank = 4\n        self.d_inner = self.expand * self.d_model\n        self.bias = False\n        self.conv_bias = True\n        self.dropout = 0.1\n        self.max_sequence_length = 256\n        self.safety_focus = True\n        self.crisis_detection = True\n        self.bidirectional = False\n        self.num_hospitals = 6\n        self.num_crisis_levels = 5\n        self.num_acuity_levels = 5\n\n# --- full HamburgMambaConfig inherits SmallConfig ---\nclass HamburgMambaConfig(SmallConfig):\n    def __init__(self):\n        super().__init__()\n        self.d_model = 512\n        self.n_layers = 12\n        # … rest of your original full config …\n        if self.dt_rank == \"auto\":\n            self.dt_rank = math.ceil(self.d_model / 16)\n        self.d_inner = int(self.expand * self.d_model)\n\n# --- your ClinicalEncoder and HybridSafetyModel classes go here ---\n# (Paste the exact definitions you already have; no emojis in code!)\n# e.g. class HamburgClinicalEncoder(nn.Module): … \n#      class HybridSafetyModel(nn.Module): …\n# and your HamburgGroundTruthGenerator + make_real_hamburg_df()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:54:12.809126Z","iopub.execute_input":"2025-08-05T04:54:12.809517Z","iopub.status.idle":"2025-08-05T04:54:12.818738Z","shell.execute_reply.started":"2025-08-05T04:54:12.809491Z","shell.execute_reply":"2025-08-05T04:54:12.817551Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport numpy as np\nimport pandas as pd\nfrom enum import Enum\n\n\n# ----------------------------\n# Simplified clinical encoder + hybrid model\n# ----------------------------\nclass HamburgClinicalEncoder(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.vital_encoder = nn.Linear(7, 32)\n        self.demographic_encoder = nn.Linear(2, 16)\n        self.hospital_embedding = nn.Embedding(config.num_hospitals + 1, 16)\n        self.acuity_embedding   = nn.Embedding(config.num_acuity_levels + 1, 16)\n        self.crisis_embedding   = nn.Embedding(config.num_crisis_levels + 1, 16)\n        self.crew_state_encoder     = nn.Linear(4, 32)\n        self.system_stress_encoder  = nn.Linear(3, 16)\n        self.safety_encoder         = nn.Linear(3, 16)\n        self.time_encoder           = nn.Linear(3, 16)\n        self.environment_encoder    = nn.Linear(2, 16)\n        self.complaint_embedding    = nn.Embedding(20, 16)\n\n        # Compute total input dim\n        total = 32 + 16 + 16 + 16 + 16 + 32 + 16 + 16 + 16 + 16 + 16\n        self.final_projection = nn.Linear(total, config.d_model)\n\n    def forward(self, patient_data):\n        # vitals\n        vitals = torch.stack([\n            patient_data['vital_heart_rate'],\n            patient_data['vital_bp_systolic'],\n            patient_data['vital_bp_diastolic'],\n            patient_data['vital_respiratory_rate'],\n            patient_data['vital_oxygen_saturation'],\n            patient_data['vital_temperature'],\n            patient_data['vital_gcs'],\n        ], dim=-1)\n        vfeat = self.vital_encoder(vitals)\n\n        # demographics\n        demo = torch.stack([patient_data['age']/100.0, patient_data['gender']], dim=-1)\n        dfeat = self.demographic_encoder(demo)\n\n        # embeddings\n        hfeat = self.hospital_embedding(patient_data['hospital_destination'])\n        afeat = self.acuity_embedding   (patient_data['acuity_level'])\n        cfeat = self.crisis_embedding   (patient_data['system_crisis_level'])\n\n        # crew\n        crew = torch.stack([\n            patient_data['crew_calls_today']/25.0,\n            patient_data['crew_hours_on_shift']/12.0,\n            patient_data['crew_fatigue_level']/2.0,\n            patient_data['burnout_risk_score'],\n        ], dim=-1)\n        crew_feat = self.crew_state_encoder(crew)\n\n        # system stress\n        stress = torch.stack([\n            patient_data['available_crews']/80.0,\n            patient_data['calls_waiting']/10.0,\n            patient_data['response_delay_minutes']/30.0,\n        ], dim=-1)\n        sfeat = self.system_stress_encoder(stress)\n\n        # safety\n        safe = torch.stack([\n            patient_data['response_delay_minutes']/30.0,\n            patient_data['handoff_quality_score'],\n            patient_data['documentation_completeness'],\n        ], dim=-1)\n        safe_feat = self.safety_encoder(safe)\n\n        # time\n        time = torch.stack([\n            patient_data['hour']/24.0,\n            patient_data['day_of_week']/7.0,\n            patient_data['shift_change_stress'],\n        ], dim=-1)\n        tfeat = self.time_encoder(time)\n\n        # environment\n        env = torch.stack([\n            patient_data['weather_impact'],\n            patient_data['tourism_factor'],\n        ], dim=-1)\n        efeat = self.environment_encoder(env)\n\n        # complaint\n        comp_feat = self.complaint_embedding(patient_data['chief_complaint_encoded'])\n\n        # concatenate\n        all_feats = torch.cat([\n            vfeat, dfeat, hfeat, afeat, cfeat,\n            crew_feat, sfeat, safe_feat, tfeat, efeat, comp_feat\n        ], dim=-1)\n        return self.final_projection(all_feats)\n\nclass HybridSafetyModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        self.encoder = HamburgClinicalEncoder(config)\n        self.backbone = nn.GRU(input_size=config.d_model,\n                               hidden_size=config.d_model,\n                               batch_first=True)\n        self.crisis_head = nn.Sequential(\n            nn.Linear(config.d_model, 64), nn.ReLU(), nn.Dropout(0.1),\n            nn.Linear(64, config.num_crisis_levels)\n        )\n        self.staff_head  = nn.Sequential(\n            nn.Linear(config.d_model, 64), nn.ReLU(),\n            nn.Linear(64, 3)\n        )\n        self.safety_head = nn.Sequential(\n            nn.Linear(config.d_model, 64), nn.ReLU(),\n            nn.Linear(64, 3)\n        )\n\n    def forward(self, patient_data):\n        x = self.encoder(patient_data)     # (B, L, d_model)\n        x, _ = self.backbone(x)            # (B, L, d_model)\n        last = x[:, -1, :]                 # (B, d_model)\n        crisis_logits = self.crisis_head(last)\n        staff_out     = self.staff_head(last)\n        safety_out    = self.safety_head(last)\n\n        return {\n            \"crisis_logits\": crisis_logits,\n            \"burnout\":       torch.sigmoid(staff_out[:, 0]),\n            \"fatigue\":       torch.sigmoid(staff_out[:, 1]) * 2.0,\n            \"retention\":     torch.sigmoid(staff_out[:, 2]),\n            \"response_delay\":F.relu(safety_out[:, 0]),\n            \"quality\":       torch.sigmoid(safety_out[:, 1]),\n            \"adverse_risk\":  torch.sigmoid(safety_out[:, 2]),\n        }\n\n# ----------------------------\n# Simplified ground-truth generator\n# ----------------------------\nclass HamburgCrisisLevel(Enum):\n    NORMAL = 0; STRESSED = 1; CRISIS = 2; BREAKDOWN = 3; STAFF_EXODUS = 4\n\nclass HamburgGroundTruthGenerator:\n    def __init__(self):\n        self.total_ambulances = 80\n    def generate_complete_ground_truth(self,\n                                       crew_calls_today:int,\n                                       crew_hours_worked:float,\n                                       system_calls_today:int,\n                                       available_crews:int,\n                                       calls_waiting:int,\n                                       hour:int):\n        if crew_calls_today>=20: lvl=HamburgCrisisLevel.BREAKDOWN\n        elif crew_calls_today>=15: lvl=HamburgCrisisLevel.CRISIS\n        elif crew_calls_today>=10: lvl=HamburgCrisisLevel.STRESSED\n        else: lvl=HamburgCrisisLevel.NORMAL\n        burnout = min(1.0, crew_calls_today/25 + crew_hours_worked/24)\n        retention = max(0.1, 1.0 - 0.5*burnout)\n        delay = 8.0*(1 + 0.3*lvl.value)\n        handoff = max(0.5, 1.0 - 0.3*burnout)\n        doc    = max(0.5, 1.0 - 0.2*burnout)\n        adv    = min(0.8, 0.5*burnout)\n        return {\n          'crisis_level': lvl.value,\n          'burnout_risk': burnout,\n          'staff_retention_probability': retention,\n          'response_delay_minutes': delay,\n          'handoff_quality_score': handoff,\n          'documentation_completeness': doc,\n          'clinical_care_quality': 1.0 - adv,\n          'adverse_event_risk': adv,\n          'crew_fatigue_level': min(2.0, crew_calls_today/12 + crew_hours_worked/12)\n        }\n\n# ----------------------------\n# Build a “real” hamburg_df\n# ----------------------------\ndef make_real_hamburg_df(num_patients=100, seq_len=16, seed=42):\n    rng = np.random.default_rng(seed)\n    gen = HamburgGroundTruthGenerator()\n    records = []\n    for pid in range(num_patients):\n        c0 = int(rng.integers(5,25))\n        h0 = float(rng.uniform(6,12))\n        s0 = int(rng.integers(800,1600))\n        a0 = int(rng.integers(20,80))\n        w0 = int(rng.integers(0,12))\n        hr0 = int(rng.integers(0,23))\n        for t in range(seq_len):\n            c = max(0, c0 + int(rng.integers(-1,2)))\n            h = min(16, max(6, h0 + rng.normal(0,0.5)))\n            s = max(500, s0 + int(rng.integers(-50,50)))\n            a = max(5, min(80, a0 + int(rng.integers(-3,3))))\n            w = max(0, w0 + int(rng.integers(-1,2)))\n            hr = (hr0 + t) % 24\n            gt = gen.generate_complete_ground_truth(\n                crew_calls_today=c,\n                crew_hours_worked=h,\n                system_calls_today=s,\n                available_crews=a,\n                calls_waiting=w,\n                hour=hr\n            )\n            records.append({\n                'patient_id': pid,\n                'time_step': t,\n                'vital_heart_rate': float(rng.normal(80,10)),\n                'vital_bp_systolic': float(rng.normal(120,15)),\n                'vital_bp_diastolic': float(rng.normal(80,10)),\n                'vital_respiratory_rate': float(rng.normal(16,2)),\n                'vital_oxygen_saturation': float(np.clip(rng.normal(98,1),90,100)),\n                'vital_temperature': float(rng.normal(37,0.5)),\n                'vital_gcs': float(np.clip(rng.normal(15,1),3,15)),\n                'age': int(rng.integers(20,90)),\n                'gender': int(rng.integers(0,2)),\n                'hospital_destination': int(rng.integers(0,6)),\n                'acuity_level': int(rng.integers(1,6)),\n                'system_crisis_level': gt['crisis_level'],\n                'crew_calls_today': c,\n                'crew_hours_on_shift': h,\n                'crew_fatigue_level': gt['crew_fatigue_level'],\n                'burnout_risk_score': gt['burnout_risk'],\n                'available_crews': a,\n                'calls_waiting': w,\n                'response_delay_minutes': gt['response_delay_minutes'],\n                'handoff_quality_score': gt['handoff_quality_score'],\n                'documentation_completeness': gt['documentation_completeness'],\n                'hour': hr,\n                'day_of_week': int(rng.integers(0,6)),\n                'shift_change_stress': float(rng.uniform(0,1)),\n                'weather_impact': float(rng.uniform(0.8,1.2)),\n                'tourism_factor': float(rng.uniform(0.9,1.1)),\n                'chief_complaint_encoded': int(rng.integers(0,20)),\n                'crisis_level': gt['crisis_level'],\n                'burnout_risk': gt['burnout_risk'],\n                'staff_retention_probability': gt['staff_retention_probability']\n            })\n    return pd.DataFrame.from_records(records)\n\n# Instantiate and inspect\nhamburg_df = make_real_hamburg_df(num_patients=100, seq_len=16)\nprint(\"hamburg_df shape:\", hamburg_df.shape)\nprint(hamburg_df.head())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:54:12.820488Z","iopub.execute_input":"2025-08-05T04:54:12.820823Z","iopub.status.idle":"2025-08-05T04:54:13.150472Z","shell.execute_reply.started":"2025-08-05T04:54:12.820798Z","shell.execute_reply":"2025-08-05T04:54:13.149513Z"}},"outputs":[{"name":"stdout","text":"hamburg_df shape: (1600, 32)\n   patient_id  time_step  vital_heart_rate  vital_bp_systolic  \\\n0           0          0         76.837574         119.747983   \n1           0          1         78.454705         113.575083   \n2           0          2         86.505928         131.148813   \n3           0          3         73.611222         115.872866   \n4           0          4         68.667128         106.208216   \n\n   vital_bp_diastolic  vital_respiratory_rate  vital_oxygen_saturation  \\\n0           71.469561               17.758796                98.777792   \n1           76.478664               17.064618                98.365444   \n2           85.431543               14.668981                98.232161   \n3           94.949413               14.268338                98.968278   \n4           84.971607               16.284851                98.690485   \n\n   vital_temperature  vital_gcs  age  ...  documentation_completeness  hour  \\\n0          37.033015  15.000000   73  ...                    0.880185     1   \n1          37.206366  15.000000   87  ...                    0.880826     2   \n2          37.058343  15.000000   35  ...                    0.888531     3   \n3          36.158565  14.665115   52  ...                    0.886128     4   \n4          36.786374  15.000000   79  ...                    0.876481     5   \n\n   day_of_week  shift_change_stress  weather_impact  tourism_factor  \\\n0            1             0.554585        0.825527        1.065526   \n1            5             0.325825        0.948184        0.993911   \n2            0             0.199908        0.802945        1.057385   \n3            3             0.559207        0.921580        0.906164   \n4            2             0.814020        0.866789        0.904542   \n\n   chief_complaint_encoded  crisis_level  burnout_risk  \\\n0                        5             0      0.599073   \n1                       15             0      0.595868   \n2                       15             0      0.557346   \n3                        6             0      0.569362   \n4                        2             0      0.617594   \n\n   staff_retention_probability  \n0                     0.700463  \n1                     0.702066  \n2                     0.721327  \n3                     0.715319  \n4                     0.691203  \n\n[5 rows x 32 columns]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"#build a tiny synthetic batch to sanity‐check forward pass:\nB, L = 2, 16\ndef rand(B,L): return torch.rand(B, L)\ndef randint(B,L,H): return torch.randint(0, H, (B, L))\n\nbatch = {\n    'vital_heart_rate':       rand(B,L),\n    'vital_bp_systolic':      rand(B,L),\n    'vital_bp_diastolic':     rand(B,L),\n    'vital_respiratory_rate': rand(B,L),\n    'vital_oxygen_saturation':rand(B,L),\n    'vital_temperature':      rand(B,L),\n    'vital_gcs':              rand(B,L),\n    'age':                    rand(B,L),\n    'gender':                 rand(B,L),\n    'hospital_destination':   randint(B,L,config.num_hospitals+1).long(),\n    'acuity_level':           randint(B,L,config.num_acuity_levels+1).long(),\n    'system_crisis_level':    randint(B,L,config.num_crisis_levels+1).long(),\n    'crew_calls_today':       rand(B,L),\n    'crew_hours_on_shift':    rand(B,L),\n    'crew_fatigue_level':     rand(B,L),\n    'burnout_risk_score':     rand(B,L),\n    'available_crews':        rand(B,L),\n    'calls_waiting':          rand(B,L),\n    'response_delay_minutes': rand(B,L),\n    'handoff_quality_score':  rand(B,L),\n    'documentation_completeness': rand(B,L),\n    'hour':                   rand(B,L),\n    'day_of_week':            rand(B,L),\n    'shift_change_stress':    rand(B,L),\n    'weather_impact':         rand(B,L),\n    'tourism_factor':         rand(B,L),\n    'chief_complaint_encoded': randint(B,L,20).long()\n}\n\n# 4) run forward\nwith torch.no_grad():\n    out = model(batch)\n\n# 5) print shapes\nprint(\"✅ Forward pass shapes:\")\nfor k,v in out.items():\n    print(f\"  {k:16s} → {tuple(v.shape)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T05:05:15.001795Z","iopub.execute_input":"2025-08-05T05:05:15.002214Z","iopub.status.idle":"2025-08-05T05:05:15.032919Z","shell.execute_reply.started":"2025-08-05T05:05:15.002191Z","shell.execute_reply":"2025-08-05T05:05:15.031605Z"}},"outputs":[{"name":"stdout","text":"✅ Forward pass shapes:\n  crisis_logits    → (2, 5)\n  burnout          → (2,)\n  fatigue          → (2,)\n  retention        → (2,)\n  response_delay   → (2,)\n  quality          → (2,)\n  adverse_risk     → (2,)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Cell 3: Prepare PyTorch Dataset + DataLoader for your real Hamburg data\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nclass HamburgSafetyDataset(Dataset):\n    def __init__(self, df, seq_len=16):\n        self.df = df.reset_index(drop=True)\n        self.seq_len = seq_len\n        # these are all the keys your model.encoder.forward expects:\n        self.features = [\n            'vital_heart_rate','vital_bp_systolic','vital_bp_diastolic',\n            'vital_respiratory_rate','vital_oxygen_saturation','vital_temperature',\n            'vital_gcs','age','gender','hospital_destination','acuity_level',\n            'system_crisis_level','crew_calls_today','crew_hours_on_shift',\n            'crew_fatigue_level','burnout_risk_score','available_crews',\n            'calls_waiting','response_delay_minutes','handoff_quality_score',\n            'documentation_completeness','hour','day_of_week',\n            'shift_change_stress','weather_impact','tourism_factor',\n            'chief_complaint_encoded'\n        ]\n        # your supervision targets at last time-step:\n        self.targets = ['crisis_level','burnout_risk','staff_retention_probability','response_delay_minutes']\n\n    def __len__(self):\n        return len(self.df) // self.seq_len\n\n    def __getitem__(self, idx):\n        chunk = self.df.iloc[idx*self.seq_len:(idx+1)*self.seq_len]\n        sample = {}\n        # pack inputs: Long for embeddings, Float for everything else\n        for feat in self.features:\n            arr = chunk[feat].values\n            tensor = torch.tensor(arr, \n                                  dtype=torch.long if feat in \n                                      ('hospital_destination','acuity_level',\n                                       'system_crisis_level','chief_complaint_encoded')\n                                  else torch.float32)\n            # shape: (seq_len,) → (1, seq_len) so model sees batch dim=1\n            sample[feat] = tensor.unsqueeze(0)\n        # extract last-step targets\n        last = chunk.iloc[-1]\n        target = {\n            'crisis_level': torch.tensor(int(last.crisis_level), dtype=torch.long),\n            'burnout_risk': torch.tensor(float(last.burnout_risk), dtype=torch.float32),\n            'retention_probability': torch.tensor(float(last.staff_retention_probability), dtype=torch.float32),\n            'response_delay_minutes': torch.tensor(float(last.response_delay_minutes), dtype=torch.float32),\n        }\n        return sample, target\n\n# split into train/val\ndataset = HamburgSafetyDataset(hamburg_df, seq_len=16)\nval_size = int(0.2 * len(dataset))\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n\n# create loaders (batch of sequences)\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\nval_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False)\n\nprint(f\"✔️  Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:57:35.538231Z","iopub.execute_input":"2025-08-05T04:57:35.538640Z","iopub.status.idle":"2025-08-05T04:57:35.552786Z","shell.execute_reply.started":"2025-08-05T04:57:35.538612Z","shell.execute_reply":"2025-08-05T04:57:35.551920Z"}},"outputs":[{"name":"stdout","text":"✔️  Train batches: 20, Val batches: 5\n","output_type":"stream"}],"execution_count":26}]}