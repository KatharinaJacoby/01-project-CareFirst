{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 \fmodern Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # 1\u65039?\u8419? Hospital & department capacity setup (UKE-focused)\line
\line
import random\line
\line
# --- ICU units (real counts) -----------------------------------------------\line
# Each ICU must reserve 1 bed for resuscitation => operational_beds = total_beds - 1\line
ICU_TOTAL_BEDS = \{\line
    "neurochirurgical_icu": 12,\line
    "neurological_icu": 12,\line
    "interdis_stage1": 12,     # UKE 1C\line
    "interdis_stage2": 12,     # UKE 1D\line
    "interdis_stage3": 12,     # UKE 1E\line
    "surgical_icu": 12,        # UKE 1F\line
    "internal_medicine_icu": 12,  # UKE 1G\line
    "cardio_icu": 12,          # UKE H1b (cardiology)\line
    "cardio_surgery_icu": 12,  # UKE H1b (cardiac surgery)\line
    "vascular_cardiac_icu": 8  # UKE H2b\line
\}\line
\line
ICU_OPERATIONAL_BEDS = \{\line
    k: max(v - 1, 0) for k, v in ICU_TOTAL_BEDS.items()\line
\}\line
\line
# --- Non-ICU departments (simulated sizes) ----------------------------------\line
# Rule of thumb: Large=50, Medium=30, Small=20\line
DEPARTMENTS_SIZE = \{\line
    # Large\line
    "internal_medicine": 50,\line
    "neurology": 50,\line
    "surgery_general": 50,\line
\line
    # Medium\line
    "cardiology": 30,\line
    "pulmonology": 30,\line
    "gastroenterology": 30,\line
    "orthopedics": 30,\line
    "surgery_trauma": 30,\line
    "vascular_surgery": 30,\line
\line
    # Small\line
    "oncology": 20,\line
    "pediatrics": 20,\line
    "obstetrics_gynecology": 20,\line
    "psychiatry": 20,\line
    "palliative": 20,\line
    "imc_internal_medicine": 20,\line
\}\line
\line
# Combine into a single capacity registry (operational bed counts)\line
OPER_BEDS = \{\line
    **ICU_OPERATIONAL_BEDS,\line
    **DEPARTMENTS_SIZE\line
\}\line
\line
# --- Availability sampling ---------------------------------------------------\line
# Availability is sampled per patient/event: 0%..50% free, with a small chance of 0% hard block\line
def sample_availability_fraction(hard_block_prob: float = 0.10) -> float:\line
    """Return a fraction of free capacity in [0.0, 0.5]. Sometimes forced to 0.0."""\line
    if random.random() < hard_block_prob:\line
        return 0.0\line
    return random.uniform(0.0, 0.5)\line
\line
def capacity_snapshot_normalized(hard_block_prob: float = 0.10) -> dict:\line
    """\line
    Produce a dict of normalized capacity scores per department (0..1),\line
    computed as available_beds / operational_beds for the current moment.\line
    """\line
    snap = \{\}\line
    for dept, oper_beds in OPER_BEDS.items():\line
        if oper_beds <= 0:\line
            snap[dept] = 0.0\line
            continue\line
        frac = sample_availability_fraction(hard_block_prob)\line
        available = int(round(oper_beds * frac))\line
        snap[dept] = available / oper_beds\line
    return snap\line
\line
# Convenience lists if needed later\line
ICU_DEPARTMENTS = list(ICU_OPERATIONAL_BEDS.keys())\line
NON_ICU_DEPARTMENTS = list(DEPARTMENTS_SIZE.keys())\line
ALL_DEPARTMENTS = list(OPER_BEDS.keys())\line
\line
# Sanity print (optional)\line
print("ICU operational beds:", ICU_OPERATIONAL_BEDS)\line
print("Non-ICU sizes:", DEPARTMENTS_SIZE)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 ICU operational beds: \{'neurochirurgical_icu': 11, 'neurological_icu': 11, 'interdis_stage1': 11, 'interdis_stage2': 11, 'interdis_stage3': 11, 'surgical_icu': 11, 'internal_medicine_icu': 11, 'cardio_icu': 11, 'cardio_surgery_icu': 11, 'vascular_cardiac_icu': 7\}\line
Non-ICU sizes: \{'internal_medicine': 50, 'neurology': 50, 'surgery_general': 50, 'cardiology': 30, 'pulmonology': 30, 'gastroenterology': 30, 'orthopedics': 30, 'surgery_trauma': 30, 'vascular_surgery': 30, 'oncology': 20, 'pediatrics': 20, 'obstetrics_gynecology': 20, 'psychiatry': 20, 'palliative': 20, 'imc_internal_medicine': 20\}\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # 2\u65039?\u8419? Patient generator using real ICU and simulated non-ICU capacities\line
\line
import uuid\line
import pandas as pd\line
import numpy as np\line
from datetime import datetime, timedelta\line
\line
# Fixed suspected conditions for now\line
SUSPECTED_CONDITIONS = [\line
    "cardiac", "respiratory", "neurological",\line
    "gastrointestinal", "oncology", "infection", "trauma"\line
]\line
\line
HOME_TYPES = ["private", "nursing_home"]\line
\line
def generate_patient():\line
    # Static patient attributes\line
    patient_id = str(uuid.uuid4())[:8]\line
    age = np.random.randint(18, 95)\line
    home_type = np.random.choice(HOME_TYPES)\line
    suspected_condition = np.random.choice(SUSPECTED_CONDITIONS)\line
    \line
    # EMS and ED timing\line
    ems_start_time = datetime(2025, 8, 7) + timedelta(\line
        hours=np.random.randint(0, 24),\line
        minutes=np.random.randint(0, 60)\line
    )\line
    ems_triage_code = np.random.randint(1, 5)  # 1=most urgent, 4=least\line
    ems_target_hospital = "UKE"\line
    ed_arrival_time = ems_start_time + timedelta(minutes=np.random.randint(5, 30))\line
\line
    # Capacity snapshot for all departments (normalized)\line
    capacities = capacity_snapshot_normalized()\line
\line
    # Target: for now, simple suitability score for ward assignment\line
    ward_assignment_suitability = np.random.uniform(0, 1)\line
\line
    # Combine all fields\line
    record = \{\line
        "patient_id": patient_id,\line
        "age": age,\line
        "home_type": home_type,\line
        "suspected_condition": suspected_condition,\line
        "ems_start_time": ems_start_time,\line
        "ems_triage_code": ems_triage_code,\line
        "ems_target_hospital": ems_target_hospital,\line
        "ed_arrival_time": ed_arrival_time,\line
    \}\line
\line
    # Add department capacities as features\line
    for dept, cap in capacities.items():\line
        record[f"cap_\{dept\}"] = cap\line
\line
    # Output target(s)\line
    record["ward_assignment_suitability"] = ward_assignment_suitability\line
\line
    return record\line
\line
def generate_dataset(n_patients=500):\line
    patients = [generate_patient() for _ in range(n_patients)]\line
    return pd.DataFrame(patients)\line
\line
# Quick test\line
df = generate_dataset(5)\line
print(df.head())\line
print("\\nShape:", df.shape)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1   patient_id  age     home_type suspected_condition      ems_start_time  \\\line
0   6e1bb0ac   19       private             cardiac 2025-08-07 11:43:00   \line
1   7f0fe7ea   49  nursing_home        neurological 2025-08-07 16:28:00   \line
2   250eac77   80  nursing_home             cardiac 2025-08-07 01:52:00   \line
3   6610a015   91  nursing_home              trauma 2025-08-07 00:54:00   \line
4   864f9fc5   73  nursing_home            oncology 2025-08-07 08:28:00   \line
\line
   ems_triage_code ems_target_hospital     ed_arrival_time  \\\line
0                3                 UKE 2025-08-07 12:05:00   \line
1                4                 UKE 2025-08-07 16:55:00   \line
2                2                 UKE 2025-08-07 02:20:00   \line
3                2                 UKE 2025-08-07 01:08:00   \line
4                3                 UKE 2025-08-07 08:45:00   \line
\line
   cap_neurochirurgical_icu  cap_neurological_icu  ...  cap_orthopedics  \\\line
0                  0.272727              0.090909  ...         0.466667   \line
1                  0.363636              0.000000  ...         0.333333   \line
2                  0.090909              0.181818  ...         0.166667   \line
3                  0.000000              0.181818  ...         0.200000   \line
4                  0.090909              0.000000  ...         0.066667   \line
\line
   cap_surgery_trauma  cap_vascular_surgery  cap_oncology  cap_pediatrics  \\\line
0            0.400000              0.433333          0.30            0.05   \line
1            0.100000              0.400000          0.30            0.45   \line
2            0.133333              0.200000          0.25            0.45   \line
3            0.300000              0.066667          0.30            0.10   \line
4            0.233333              0.100000          0.25            0.10   \line
\line
   cap_obstetrics_gynecology  cap_psychiatry  cap_palliative  \\\line
0                       0.15            0.15            0.10   \line
1                       0.35            0.35            0.00   \line
2                       0.30            0.00            0.50   \line
3                       0.35            0.45            0.45   \line
4                       0.50            0.50            0.35   \line
\line
   cap_imc_internal_medicine  ward_assignment_suitability  \line
0                       0.50                     0.253762  \line
1                       0.10                     0.115395  \line
2                       0.35                     0.559822  \line
3                       0.35                     0.346540  \line
4                       0.10                     0.242876  \line
\line
[5 rows x 34 columns]\line
\line
Shape: (5, 34)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # Cell \u8220"3A\u8221" \u8212- ICU mapping + label functions\line
# ICU preference by condition (simple, editable)\line
ICU_PREFS = \{\line
    "cardiac": ["cap_cardio_icu", "cap_cardio_surgery_icu", "cap_vascular_cardiac_icu"],\line
    "respiratory": ["cap_internal_medicine_icu", "cap_interdis_stage1", "cap_interdis_stage2", "cap_interdis_stage3"],\line
    "neurological": ["cap_neurological_icu", "cap_neurochirurgical_icu", "cap_interdis_stage1"],\line
    "infection": ["cap_internal_medicine_icu", "cap_interdis_stage2"],\line
    "trauma": ["cap_surgical_icu", "cap_interdis_stage3"],\line
    "oncology": ["cap_internal_medicine_icu", "cap_interdis_stage2"],\line
    "gastrointestinal": ["cap_surgical_icu", "cap_internal_medicine_icu"]\line
\}\line
\line
def best_relevant_icu_capacity(rec: dict) -> float:\line
    """Return the max normalized capacity across relevant ICUs for this condition."""\line
    cond = rec["suspected_condition"]\line
    keys = ICU_PREFS.get(cond, [])\line
    if not keys:\line
        return 0.0\line
    vals = [float(rec.get(k, 0.0)) for k in keys]\line
    return max(vals) if vals else 0.0\line
\line
def synth_icu_labels(rec: dict) -> dict:\line
    """\line
    Make labels depend on ICU capacity + acuity.\line
    - icu_assignment_suitability: higher if relevant ICU has capacity.\line
    - icu_bottleneck_risk: high when relevant ICU is near zero.\line
    - pathway_latency_min: inflates when bottleneck risk is high (ED boarding).\line
    - route_plan: EMS\u8594?ICU if urgent and capacity; else EMS\u8594?ED\u8594?ICU.\line
    """\line
    cap_rel = best_relevant_icu_capacity(rec)            # 0..1\line
    triage = int(rec["ems_triage_code"])                 # 1 (most urgent) .. 4\line
    urgent = (triage <= 2)\line
\line
    # Suitability: base + positive weight on relevant ICU capacity, small noise\line
    base_by_cond = \{\line
        "cardiac": 0.70, "respiratory": 0.68, "neurological": 0.67,\line
        "infection": 0.62, "trauma": 0.66, "oncology": 0.60, "gastrointestinal": 0.63\line
    \}\line
    base = base_by_cond.get(rec["suspected_condition"], 0.62)\line
    suitability = base + 0.35*cap_rel - (0.05 if urgent and cap_rel < 0.15 else 0.0)\line
    suitability = float(np.clip(suitability + np.random.normal(0, 0.03), 0, 1))\line
\line
    # Bottleneck risk: inverse of capacity with urgency emphasis\line
    bottleneck = 1.0 - cap_rel\line
    if urgent:\line
        bottleneck = np.clip(bottleneck + 0.05, 0, 1)\line
\line
    # Latency model (minutes): base + penalty for bottleneck\line
    # Base ~ 60\u8211-120 min; add 120\u8211-240 min when bottleneck high (boarding)\line
    base_latency = np.random.uniform(60, 120)\line
    penalty = np.interp(bottleneck, [0, 1], [0, np.random.uniform(120, 240)])\line
    pathway_latency_min = float(base_latency + penalty)\line
\line
    # Route plan decision\line
    if urgent and cap_rel >= 0.25:\line
        route_plan = "EMS\u8594?ICU"\line
    else:\line
        route_plan = "EMS\u8594?ED\u8594?ICU"\line
\line
    return \{\line
        "icu_assignment_suitability": suitability,\line
        "icu_bottleneck_risk": float(np.clip(bottleneck, 0, 1)),\line
        "pathway_latency_min": pathway_latency_min,\line
        "route_plan": route_plan\line
    \}\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # Cell 3B \u8212- Patch generate_patient() to use ICU-driven labels\line
# --- ICU preferences by suspected condition\line
ICU_PREFS = \{\line
    "cardiac": ["cap_cardio_icu","cap_cardio_surgery_icu","cap_vascular_cardiac_icu"],\line
    "respiratory": ["cap_internal_medicine_icu","cap_interdis_stage1","cap_interdis_stage2","cap_interdis_stage3"],\line
    "neurological": ["cap_neurological_icu","cap_neurochirurgical_icu","cap_interdis_stage1"],\line
    "infection": ["cap_internal_medicine_icu","cap_interdis_stage2"],\line
    "trauma": ["cap_surgical_icu","cap_interdis_stage3"],\line
    "oncology": ["cap_internal_medicine_icu","cap_interdis_stage2"],\line
    "gastrointestinal": ["cap_surgical_icu","cap_internal_medicine_icu"],\line
\}\line
\line
def best_relevant_icu_capacity(rec: dict) -> float:\line
    keys = ICU_PREFS.get(rec["suspected_condition"], [])\line
    vals = [float(rec.get(k, 0.0)) for k in keys]\line
    return max(vals) if vals else 0.0\line
\line
def synth_icu_labels(rec: dict) -> dict:\line
    cap_rel = best_relevant_icu_capacity(rec)  # 0..1\line
    triage = int(rec["ems_triage_code"])\line
    urgent = (triage <= 2)\line
\line
    # base suitability by condition\line
    base = \{\line
        "cardiac":0.70,"respiratory":0.68,"neurological":0.67,\line
        "infection":0.62,"trauma":0.66,"oncology":0.60,"gastrointestinal":0.63\line
    \}.get(rec["suspected_condition"], 0.62)\line
\line
    suitability = base + 0.35*cap_rel - (0.05 if urgent and cap_rel < 0.15 else 0.0)\line
    suitability = float(np.clip(suitability + np.random.normal(0,0.03), 0, 1))\line
\line
    bottleneck = 1.0 - cap_rel\line
    if urgent:\line
        bottleneck = np.clip(bottleneck + 0.05, 0, 1)\line
\line
    base_latency = np.random.uniform(60, 120)  # base in minutes\line
    penalty = np.interp(bottleneck, [0,1], [0, np.random.uniform(120,240)])\line
    pathway_latency_min = float(base_latency + penalty)\line
\line
    route_plan = "EMS\u8594?ICU" if (urgent and cap_rel >= 0.25) else "EMS\u8594?ED\u8594?ICU"\line
\line
    return \{\line
        "icu_assignment_suitability": suitability,\line
        "icu_bottleneck_risk": float(bottleneck),\line
        "pathway_latency_min": pathway_latency_min,\line
        "route_plan": route_plan\line
    \}\line
\line
# --- Updated generator with ICU + Non-ICU capacities and ICU labels\line
def generate_patient():\line
    patient_id = str(uuid.uuid4())[:8]\line
\line
    # Demographics\line
    age = np.random.randint(18, 95)\line
    home_type = random.choice(['private', 'nursing_home'])\line
\line
    # Clinical presentation\line
    suspected_condition = random.choice([\line
        'cardiac', 'respiratory', 'neurological',\line
        'infection', 'trauma', 'oncology', 'gastrointestinal'\line
    ])\line
\line
    # EMS & ED timing\line
    ems_start_time = datetime(2025, 8, 7) + timedelta(\line
        hours=np.random.randint(0, 24),\line
        minutes=np.random.randint(0, 60)\line
    )\line
    ems_triage_code = np.random.choice([1, 2, 3, 4], p=[0.15, 0.35, 0.35, 0.15])\line
    ems_target_hospital = "UKE"\line
    ed_arrival_time = ems_start_time + timedelta(minutes=np.random.randint(5, 25))\line
\line
    day_of_week = ed_arrival_time.strftime("%A")\line
    hour_of_day = ed_arrival_time.hour\line
\line
    # ICU capacities (n-1 beds operational)\line
    icu_capacities = \{\line
        'neurochirurgical_icu': 11,\line
        'neurological_icu': 11,\line
        'interdis_stage1': 11,\line
        'interdis_stage2': 11,\line
        'interdis_stage3': 11,\line
        'surgical_icu': 11,\line
        'internal_medicine_icu': 11,\line
        'cardio_icu': 11,\line
        'cardio_surgery_icu': 11,\line
        'vascular_cardiac_icu': 7\line
    \}\line
    icu_caps = \{f"cap_\{k\}": round(np.random.randint(0, beds + 1) / beds, 2)\line
                for k, beds in icu_capacities.items()\}\line
\line
    # Non-ICU capacities (0\u8211-50% availability)\line
    non_icu_sizes = \{\line
        'internal_medicine': 50, 'neurology': 50, 'surgery_general': 50,\line
        'cardiology': 30, 'pulmonology': 30, 'gastroenterology': 30,\line
        'orthopedics': 30, 'surgery_trauma': 30, 'vascular_surgery': 30,\line
        'oncology': 20, 'pediatrics': 20, 'obstetrics_gynecology': 20,\line
        'psychiatry': 20, 'palliative': 20, 'imc_internal_medicine': 20\line
    \}\line
    non_icu_caps = \{f"cap_\{k\}": round(np.random.randint(0, int(beds*0.5) + 1) / beds, 2)\line
                    for k, beds in non_icu_sizes.items()\}\line
\line
    # Assemble record\line
    record = \{\line
        "patient_id": patient_id,\line
        "age": age,\line
        "home_type": home_type,\line
        "suspected_condition": suspected_condition,\line
        "ems_start_time": ems_start_time,\line
        "ems_triage_code": int(ems_triage_code),\line
        "ems_target_hospital": ems_target_hospital,\line
        "ed_arrival_time": ed_arrival_time,\line
        "day_of_week": day_of_week,\line
        "hour_of_day": hour_of_day,\line
        **icu_caps,\line
        **non_icu_caps,\line
    \}\line
\line
    # ICU-driven labels\line
    record.update(synth_icu_labels(record))\line
    return record\line
\line
\line
\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # Cell 4 \u8212- Regenerate dataset (now includes ICU-driven labels)\line
\line
# Rebuild a fresh dataset with ICU-driven labels\line
df = pd.DataFrame(generate_dataset(n_patients=500))\line
\line
# quick hygiene\line
assert df.isna().sum().sum() == 0\line
assert (df["ems_triage_code"].between(1,4)).all()\line
print(df.shape, "cols:", len(df.columns))\line
display(df.head(2)[[\line
    "suspected_condition","ems_triage_code","icu_assignment_suitability",\line
    "icu_bottleneck_risk","pathway_latency_min","route_plan"\line
]])\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 (500, 39) cols: 39\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1   suspected_condition  ems_triage_code  icu_assignment_suitability  \\\line
0           infection                3                    0.645189   \line
1            oncology                3                    0.716335   \line
\line
   icu_bottleneck_risk  pathway_latency_min  route_plan  \line
0                 0.91           289.542891  EMS\u8594?ED\u8594?ICU  \line
1                 0.64           153.635878  EMS\u8594?ED\u8594?ICU  \par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # Cell 5 \u8212- Feature setup\line
\line
FEATS_CAT = ["home_type", "suspected_condition", "day_of_week"]\line
FEATS_NUM = [\line
    "age", "ems_triage_code", "hour_of_day"\line
] + [c for c in df.columns if c.startswith("cap_")]\line
TARGETS = ["icu_assignment_suitability", "icu_bottleneck_risk"]\line
\line
X = df[FEATS_CAT + FEATS_NUM]\line
y = df[TARGETS]\line
\line
# Split\line
X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.4, random_state=42)\line
X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=42)\line
\line
# Preprocessor\line
pre = ColumnTransformer([\line
    ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), FEATS_CAT),\line
    ("num", StandardScaler(), FEATS_NUM)\line
])\line
\line
Xtr_np = pre.fit_transform(X_train)\line
Xva_np = pre.transform(X_val)\line
Xte_np = pre.transform(X_test)\line
\line
ytr_np = y_train.values.astype("float32")\line
yva_np = y_val.values.astype("float32")\line
yte_np = y_test.values.astype("float32")\line
\line
print("Shapes:", Xtr_np.shape, Xva_np.shape, Xte_np.shape)\line
\line
# \u55357?\u56550? 2 \u8212- Torch datasets\line
Xtr_t = torch.tensor(Xtr_np, dtype=torch.float32)\line
ytr_t = torch.tensor(ytr_np, dtype=torch.float32)\line
Xva_t = torch.tensor(Xva_np, dtype=torch.float32)\line
yva_t = torch.tensor(yva_np, dtype=torch.float32)\line
Xte_t = torch.tensor(Xte_np, dtype=torch.float32)\line
yte_t = torch.tensor(yte_np, dtype=torch.float32)\line
\line
train_loader = DataLoader(TensorDataset(Xtr_t, ytr_t), batch_size=64, shuffle=True)\line
val_loader   = DataLoader(TensorDataset(Xva_t, yva_t), batch_size=256)\line
test_loader  = DataLoader(TensorDataset(Xte_t, yte_t), batch_size=256)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 Shapes: (300, 39) (100, 39) (100, 39)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # \u55357?\u56550? 3 \u8212- Multi-task model\line
class MLP_MultiTask(nn.Module):\line
    def __init__(self, d_in, hidden1=128, hidden2=64):\line
        super().__init__()\line
        self.shared = nn.Sequential(\line
            nn.Linear(d_in, hidden1), nn.ReLU(), nn.Dropout(0.1),\line
            nn.Linear(hidden1, hidden2), nn.ReLU()\line
        )\line
        # Heads\line
        self.head_assign = nn.Linear(hidden2, 1)  # icu_assignment_suitability\line
        self.head_bottle = nn.Linear(hidden2, 1)  # icu_bottleneck_risk\line
\line
    def forward(self, x):\line
        shared_out = self.shared(x)\line
        out_assign = self.head_assign(shared_out)\line
        out_bottle = self.head_bottle(shared_out)\line
        return out_assign, out_bottle\line
\line
input_dim = Xtr_np.shape[1]\line
model = MLP_MultiTask(input_dim)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # \u55357?\u56550? 4 \u8212- Training loop\line
criterion = nn.MSELoss()\line
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\line
\line
best_val = float("inf")\line
patience, bad = 8, 0\line
\line
for epoch in range(1, 51):\line
    # Train\line
    model.train(); train_loss = 0\line
    for xb, yb in train_loader:\line
        optimizer.zero_grad()\line
        pred_assign, pred_bottle = model(xb)\line
        loss1 = criterion(pred_assign, yb[:, [0]])\line
        loss2 = criterion(pred_bottle, yb[:, [1]])\line
        loss = loss1 + loss2  # equal weighting\line
        loss.backward()\line
        optimizer.step()\line
        train_loss += loss.item() * xb.size(0)\line
    train_loss /= len(train_loader.dataset)\line
\line
    # Val\line
    model.eval(); val_loss = 0\line
    with torch.no_grad():\line
        for xb, yb in val_loader:\line
            pred_assign, pred_bottle = model(xb)\line
            loss1 = criterion(pred_assign, yb[:, [0]])\line
            loss2 = criterion(pred_bottle, yb[:, [1]])\line
            loss = loss1 + loss2\line
            val_loss += loss.item() * xb.size(0)\line
    val_loss /= len(val_loader.dataset)\line
\line
    print(f"Epoch \{epoch:02d\} | Train \{train_loss:.4f\} | Val \{val_loss:.4f\}")\line
\line
    if val_loss < best_val - 1e-6:\line
        best_val = val_loss\line
        best_state = \{k: v.cpu().clone() for k,v in model.state_dict().items()\}\line
        bad = 0\line
    else:\line
        bad += 1\line
        if bad >= patience:\line
            print("Early stopping")\line
            break\line
\line
model.load_state_dict(best_state)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 Epoch 01 | Train 0.4792 | Val 0.2642\line
Epoch 02 | Train 0.1680 | Val 0.1062\line
Epoch 03 | Train 0.1184 | Val 0.1455\line
Epoch 04 | Train 0.1178 | Val 0.1075\line
Epoch 05 | Train 0.0778 | Val 0.0893\line
Epoch 06 | Train 0.0695 | Val 0.0853\line
Epoch 07 | Train 0.0659 | Val 0.0756\line
Epoch 08 | Train 0.0591 | Val 0.0711\line
Epoch 09 | Train 0.0541 | Val 0.0750\line
Epoch 10 | Train 0.0505 | Val 0.0736\line
Epoch 11 | Train 0.0479 | Val 0.0684\line
Epoch 12 | Train 0.0449 | Val 0.0660\line
Epoch 13 | Train 0.0445 | Val 0.0639\line
Epoch 14 | Train 0.0396 | Val 0.0673\line
Epoch 15 | Train 0.0402 | Val 0.0662\line
Epoch 16 | Train 0.0379 | Val 0.0646\line
Epoch 17 | Train 0.0356 | Val 0.0639\line
Epoch 18 | Train 0.0328 | Val 0.0629\line
Epoch 19 | Train 0.0301 | Val 0.0634\line
Epoch 20 | Train 0.0324 | Val 0.0631\line
Epoch 21 | Train 0.0292 | Val 0.0646\line
Epoch 22 | Train 0.0290 | Val 0.0628\line
Epoch 23 | Train 0.0264 | Val 0.0611\line
Epoch 24 | Train 0.0232 | Val 0.0626\line
Epoch 25 | Train 0.0233 | Val 0.0627\line
Epoch 26 | Train 0.0208 | Val 0.0644\line
Epoch 27 | Train 0.0223 | Val 0.0638\line
Epoch 28 | Train 0.0198 | Val 0.0653\line
Epoch 29 | Train 0.0180 | Val 0.0635\line
Epoch 30 | Train 0.0183 | Val 0.0637\line
Epoch 31 | Train 0.0162 | Val 0.0635\line
Early stopping\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 <All keys matched successfully>\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # \u55357?\u56550? 5 \u8212- Test evaluation\line
model.eval()\line
assign_preds, bottle_preds = [], []\line
with torch.no_grad():\line
    for xb, _ in test_loader:\line
        pa, pb = model(xb)\line
        assign_preds.append(pa.cpu().numpy())\line
        bottle_preds.append(pb.cpu().numpy())\line
\line
assign_preds = np.vstack(assign_preds).ravel()\line
bottle_preds = np.vstack(bottle_preds).ravel()\line
\line
mse_assign = mean_squared_error(yte_np[:, 0], assign_preds)\line
mae_assign = mean_absolute_error(yte_np[:, 0], assign_preds)\line
mse_bottle = mean_squared_error(yte_np[:, 1], bottle_preds)\line
mae_bottle = mean_absolute_error(yte_np[:, 1], bottle_preds)\line
\line
print(f"Assignment suitability \u8594? MSE \{mse_assign:.4f\} | MAE \{mae_assign:.4f\}")\line
print(f"Bottleneck risk       \u8594? MSE \{mse_bottle:.4f\} | MAE \{mae_bottle:.4f\}")\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 Assignment suitability \u8594? MSE 0.0117 | MAE 0.0902\line
Bottleneck risk       \u8594? MSE 0.0565 | MAE 0.1927\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # Per-head test metrics\line
from sklearn.metrics import mean_squared_error, mean_absolute_error\line
model.eval()\line
with torch.no_grad():\line
    pa, pb = [], []\line
    for xb, _ in test_loader:\line
        a, b = model(xb)\line
        pa.append(a.cpu().numpy()); pb.append(b.cpu().numpy())\line
assign_preds = np.vstack(pa).ravel()\line
bottle_preds = np.vstack(pb).ravel()\line
\line
mse_assign = mean_squared_error(yte_np[:,0], assign_preds)\line
mae_assign = mean_absolute_error(yte_np[:,0], assign_preds)\line
mse_bottle = mean_squared_error(yte_np[:,1], bottle_preds)\line
mae_bottle = mean_absolute_error(yte_np[:,1], bottle_preds)\line
print(f"Assign MSE \{mse_assign:.4f\} | MAE \{mae_assign:.4f\}")\line
print(f"Bottle MSE \{mse_bottle:.4f\} | MAE \{mae_bottle:.4f\}")\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 Assign MSE 0.0117 | MAE 0.0902\line
Bottle MSE 0.0565 | MAE 0.1927\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # Reuse 'pre' and the fitted transformer from earlier. Check that ICU capacity now matters (quick permutation on assignment head)\line
cat_names = pre.named_transformers_["cat"].get_feature_names_out(FEATS_CAT)\line
num_names = np.array(FEATS_NUM, dtype=str)\line
feature_names = np.concatenate([cat_names, num_names])\line
\line
def predict_assign_numpy(X_np):\line
    t = torch.tensor(X_np, dtype=torch.float32)\line
    model.eval()\line
    with torch.no_grad():\line
        a, _ = model(t)\line
    return a.cpu().numpy().ravel()\line
\line
from sklearn.metrics import mean_squared_error\line
import numpy as np, pandas as pd\line
\line
base = mean_squared_error(yte_np[:,0], predict_assign_numpy(Xte_np))\line
drops = []\line
Xperm = Xte_np.copy()\line
rng = np.random.default_rng(42)\line
for j in range(Xperm.shape[1]):\line
    col = Xperm[:, j].copy()\line
    rng.shuffle(Xperm[:, j])\line
    mse = mean_squared_error(yte_np[:,0], predict_assign_numpy(Xperm))\line
    drops.append(mse - base)\line
    Xperm[:, j] = col\line
\line
imp = pd.DataFrame(\{"feature": feature_names, "mse_increase": drops\}).sort_values("mse_increase", ascending=False)\line
display(imp.head(15))\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1                              feature  mse_increase\line
19                  cap_surgical_icu      0.001793\line
2        suspected_condition_cardiac      0.001591\line
31                cap_surgery_trauma      0.001273\line
0             home_type_nursing_home      0.001192\line
18               cap_interdis_stage3      0.001161\line
15              cap_neurological_icu      0.001051\line
1                  home_type_private      0.000893\line
21                    cap_cardio_icu      0.000785\line
36                    cap_psychiatry      0.000756\line
38         cap_imc_internal_medicine      0.000711\line
12                   ems_triage_code      0.000688\line
32              cap_vascular_surgery      0.000678\line
17               cap_interdis_stage2      0.000644\line
20         cap_internal_medicine_icu      0.000531\line
5   suspected_condition_neurological      0.000464\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # --- Combined P1-P3: ICU-aware permutation importance (numeric only) ---\line
from sklearn.inspection import permutation_importance\line
import numpy as np\line
\line
# Use the same numeric test set you trained on\line
X_test_np = X_test.values.astype(np.float32)  # assumes X_test is already one-hot encoded\line
y_test_np = y_test.values.astype(np.float32)\line
\line
# 1. Baseline test MSE\line
y_pred_np = model(torch.tensor(X_test_np)).detach().numpy().ravel()\line
baseline_mse = mean_squared_error(y_test_np, y_pred_np)\line
print(f"Baseline test MSE: \{baseline_mse:.4f\}")\line
\line
# 2. Permutation importance\line
def model_predict(X):\line
    X_t = torch.tensor(X, dtype=torch.float32)\line
    return model(X_t).detach().numpy().ravel()\line
\line
perm_results = permutation_importance(\line
    estimator=model_predict,\line
    X=X_test_np,\line
    y=y_test_np,\line
    scoring="neg_mean_squared_error",\line
    n_repeats=10,\line
    random_state=42\line
)\line
\line
# Build DataFrame\line
perm_df = pd.DataFrame(\{\line
    "feature": feature_names,  # from your encoder / preprocessing step\line
    "mse_increase": -perm_results.importances_mean\line
\}).sort_values(by="mse_increase", ascending=False)\line
\line
print("\\nTop features by permutation importance:")\line
display(perm_df.head(15))\line
\line
# 3. Group features\line
icu_cols = [f for f in feature_names if f.startswith("cap_") and "_icu" in f]\line
non_icu_cols = [f for f in feature_names if f.startswith("cap_") and "_icu" not in f]\line
other_cols = [f for f in feature_names if f not in icu_cols + non_icu_cols]\line
\line
def group_importance(cols, label):\line
    return \{\line
        "group": label,\line
        "perm_mse_increase": perm_df.loc[perm_df["feature"].isin(cols), "mse_increase"].mean()\line
    \}\line
\line
group_df = pd.DataFrame([\line
    group_importance(icu_cols, "ICU capacity"),\line
    group_importance(non_icu_cols, "Non-ICU capacity"),\line
    group_importance(other_cols, "Other")\line
])\line
\line
print("\\nGroup-level permutation importance:")\line
display(group_df.sort_values(by="perm_mse_increase", ascending=False))\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 ---------------------------------------------------------------------------\line
ValueError                                Traceback (most recent call last)\line
/tmp/ipykernel_36/518699289.py in <cell line: 0>()\line
      4 \line
      5 # Use the same numeric test set you trained on\line
----> 6 X_test_np = X_test.values.astype(np.float32)  # assumes X_test is already one-hot encoded\line
      7 y_test_np = y_test.values.astype(np.float32)\line
      8 \line
\line
ValueError: could not convert string to float: 'private'\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # Cell PI-2 \u8212- Permutation importance (on test set)\line
from sklearn.metrics import mean_squared_error\line
import pandas as pd\line
import matplotlib.pyplot as plt\line
\line
def permutation_importance_torch(predict_fn, X, y, n_repeats=10, seed=42):\line
    rng = np.random.default_rng(seed)\line
    baseline = mean_squared_error(y, predict_fn(X))\line
    importances = np.zeros(X.shape[1], dtype=float)\line
\line
    for j in range(X.shape[1]):\line
        losses = []\line
        X_perm = X.copy()\line
        for _ in range(n_repeats):\line
            rng.shuffle(X_perm[:, j])   # in-place column shuffle\line
            y_hat = predict_fn(X_perm)\line
            losses.append(mean_squared_error(y, y_hat))\line
        importances[j] = np.mean(losses) - baseline\line
    return importances, baseline\line
\line
imps, base_mse = permutation_importance_torch(mlp_predict_numpy, X_test_np, y_test_np, n_repeats=20)\line
\line
imp_df = pd.DataFrame(\{\line
    "feature": feature_names,\line
    "perm_mse_increase": imps\line
\}).sort_values("perm_mse_increase", ascending=False)\line
\line
print(f"Baseline test MSE: \{base_mse:.4f\}")\line
display(imp_df.head(20))\line
\line
# Plot top 15\line
top = imp_df.head(15).iloc[::-1]  # reverse for nicer barh\line
plt.figure(figsize=(8, 6))\line
plt.barh(top["feature"], top["perm_mse_increase"])\line
plt.xlabel("MSE increase when permuted")\line
plt.title("Permutation Importance (Test set) \u8212- Top 15 features")\line
plt.tight_layout()\line
plt.show()\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 # \u55357?\u56590? Combined P1\u8211-P3: Permutation importance on ICU assignment head (uses encoded test set)\line
\line
import numpy as np, pandas as pd, torch\line
from sklearn.metrics import mean_squared_error\line
import matplotlib.pyplot as plt\line
\line
# 0) Preconditions / guardrails\line
assert 'pre_torch' in globals(), "pre_torch (fitted ColumnTransformer) not found."\line
assert 'Xte_np' in globals() and 'yte_np' in globals(), "Use the encoded test arrays from preprocessing."\line
assert 'model' in globals(), "Trained model not found."\line
\line
# 1) Recover feature names from fitted encoder\line
cat_names = pre_torch.named_transformers_['cat'].get_feature_names_out(FEATS_CAT)\line
num_names = np.array(FEATS_NUM, dtype=str)\line
feature_names = np.concatenate([cat_names, num_names])\line
\line
assert feature_names.shape[0] == Xte_np.shape[1], f"Feature name count \{feature_names.shape[0]\} != X cols \{Xte_np.shape[1]\}"\line
\line
# 2) Predict helper for the ICU assignment head (target column 0)\line
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")\line
model.eval(); model.to(device)\line
\line
def predict_assign_numpy(X_np: np.ndarray) -> np.ndarray:\line
    X_t = torch.tensor(X_np, dtype=torch.float32, device=device)\line
    with torch.no_grad():\line
        out = model(X_t)\line
        # Handle multi-task vs single-task models\line
        if isinstance(out, (tuple, list)):   # multi-task: (assign, bottle, ...)\line
            assign = out[0]\line
        else:                                 # single head model\line
            assign = out\line
    return assign.detach().cpu().numpy().ravel()\line
\line
# 3) Baseline test MSE for assignment head\line
y_true = yte_np[:, 0]  # ICU assignment target\line
y_pred = predict_assign_numpy(Xte_np)\line
baseline_mse = mean_squared_error(y_true, y_pred)\line
print(f"Baseline test MSE (assignment): \{baseline_mse:.4f\}")\line
\line
# 4) Permutation importance (manual, robust)\line
rng = np.random.default_rng(42)\line
n_repeats = 10\line
mse_increase = np.zeros(Xte_np.shape[1], dtype=float)\line
\line
for j in range(Xte_np.shape[1]):\line
    losses = []\line
    for _ in range(n_repeats):\line
        X_perm = Xte_np.copy()\line
        rng.shuffle(X_perm[:, j])  # in-place column shuffle\line
        yp = predict_assign_numpy(X_perm)\line
        losses.append(mean_squared_error(y_true, yp))\line
    mse_increase[j] = np.mean(losses) - baseline_mse\line
\line
imp_df = pd.DataFrame(\{"feature": feature_names, "mse_increase": mse_increase\})\line
imp_df = imp_df.sort_values("mse_increase", ascending=False)\line
display(imp_df.head(20))\line
\line
# 5) Grouped importance (ICU capacity vs Non-ICU capacity vs Other)\line
icu_mask = np.array([f.startswith("cap_") and "_icu" in f for f in feature_names])\line
nonicu_mask = np.array([f.startswith("cap_") and "_icu" not in f for f in feature_names])\line
other_mask = ~(icu_mask | nonicu_mask)\line
\line
group_df = pd.DataFrame(\{\line
    "group": ["ICU capacity", "Non-ICU capacity", "Other"],\line
    "mean_perm_mse_increase": [\line
        imp_df.loc[icu_mask, "mse_increase"].mean(),\line
        imp_df.loc[nonicu_mask, "mse_increase"].mean(),\line
        imp_df.loc[other_mask, "mse_increase"].mean(),\line
]\})\line
display(group_df.sort_values("mean_perm_mse_increase", ascending=False))\line
\line
# 6) Quick plot of top-15 features (optional)\line
top = imp_df.head(15).iloc[::-1]\line
plt.figure(figsize=(8, 6))\line
plt.barh(top["feature"], top["mse_increase"])\line
plt.xlabel("MSE increase when permuted")\line
plt.title("Permutation Importance (ICU assignment head) \u8212- Top 15")\line
plt.tight_layout()\line
plt.show()\par}
}
